{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ATTENTION:\n",
    "\n",
    "All submissions must be uploaded as .ipynb notebooks (Jupyter Notebook), unless specifically stated otherwise.\n",
    "Other file extensions are not allowed and ignored for submission 'grading'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install [Anaconda](https://www.anaconda.com/products/distribution)\n",
    "\n",
    "Make sure that Python 3.9 is installed.\n",
    "\n",
    "Install the following packages:\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy matrix basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize a numpy array of size (12, 4) and name it 'test'\n",
    "# The values of the initalized array are to be created from a random normal distribution\n",
    "\n",
    "# Code here (one line)\n",
    "test = np.random.randn(12, 4)\n",
    "\n",
    "# Transpose the matrix 'test' and override the initial matrix\n",
    "\n",
    "# Code here (one line)\n",
    "test = test.T\n",
    "\n",
    "# Create a new numpy array of size (4, 3) and name it 'test_2' (initialized with a random uniform distribution with a low value of 0.1 and a high value of 0.9)\n",
    "# Multiply (matrix multiplication) the matrix 'test' with the matrix 'test_2' respectively, and name the resulting matrix 'result'\n",
    "# Hint: Transpose the matrix above back to make the multiplication work\n",
    "\n",
    "# Code here\n",
    "test = test.T\n",
    "test_2 = np.random.uniform(low=0.1, high=0.9, size=(4, 3))\n",
    "result = np.matmul(test, test_2)\n",
    "\n",
    "# Print the size (shape) of your 'result' matrix\n",
    "print(\"Result shape:\", result.shape)\n",
    "\n",
    "# Slice the matrix 'result' so that\n",
    " # 1: the first until the fifth index of the first dimension and the last index of the second dimension are used (result matrix shape == (5, ))\n",
    " # 2: the last index of the first dimension and all indices of the second dimension are used (result matrix shape == (3,))\n",
    " # 3: every second index of the first dimension (starting from index 1 - NOT 0) and the first index of the second dimension are used (result matrix shape == (6,))\n",
    "\n",
    "# Code here\n",
    "slice_1 = result[0:5, -1]\n",
    "slice_2 = result[-1, :]\n",
    "slice_3 = result[1::2, 0]\n",
    "\n",
    "print(\"Slice 1 shape:\", slice_1.shape)\n",
    "print(\"Slice 2 shape:\", slice_2.shape)\n",
    "print(\"Slice 3 shape:\", slice_3.shape)\n",
    "\n",
    "# Find the maximum of the matrix 'result' in every dimension, so that the size of the first dimension stays the same and the second dimension is of size 1 (result matrix shape == (12,))\n",
    "# Use a numpy pre-implemented function for it and name the resulting matrix 'max_result'\n",
    "\n",
    "# Code here\n",
    "max_result = np.max(result, axis=1)\n",
    "print(\"Max result shape:\", max_result.shape)\n",
    "\n",
    "# Find the dimensional information where the max values are positioned in the 'result' matrix with a numpy function. Name the result matrix 'max_result_2'\n",
    "# Use the dimensional information and slice the 'result' matrix by this information (neatly in a one-liner)\n",
    "\n",
    "# Code here\n",
    "max_indices = np.argmax(result, axis=1)\n",
    "max_result_2 = result[np.arange(result.shape[0]), max_indices]\n",
    "\n",
    "# Compare max_result and max_result_2. Are they the same?\n",
    "# The comparison between the two matrix should either be True or False (not an array of True of False values)\n",
    "\n",
    "# Code here\n",
    "comparison = np.all(max_result == max_result_2)\n",
    "print(\"Are max_result and max_result_2 the same?\", comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with the Feed forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the forward pass of the following neural network structure\n",
    "# The arrows show only in the forward direction (we discuss backprogation later)\n",
    "# More instructions below the image\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='feed_forward.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the following initializations are to be created with a random normal distribution\n",
    "\n",
    "# Initialize the layers and name them w_0, w_1 and w_2\n",
    "# w_0 is connected to the input (left side), w_1 is the middle part of the network and w_2 is connected to the output (right side)\n",
    "# The layers are no vectors! The layers represent an input dimension and output dimension and are therefore matrices!\n",
    "\n",
    "# Code here\n",
    "# Assuming a typical structure: input(2) -> hidden1(4) -> hidden2(3) -> output(1)\n",
    "w_0 = np.random.randn(2, 4)  # Input layer to first hidden layer\n",
    "w_1 = np.random.randn(4, 3)  # First hidden layer to second hidden layer\n",
    "w_2 = np.random.randn(3, 1)  # Second hidden layer to output\n",
    "\n",
    "# Use the vector _input as the network's input\n",
    "_input = np.random.randn(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the matrix multiplications to get the output (print the output)\n",
    "\n",
    "# Code here\n",
    "hidden_1 = np.matmul(_input, w_0)\n",
    "hidden_2 = np.matmul(hidden_1, w_1)\n",
    "output = np.matmul(hidden_2, w_2)\n",
    "\n",
    "print(\"Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all weight except one path to zero and compare the result of the output to your own (path) calculations.\n",
    "# A path is defined here as one input to output connection by passing only one node per layer.\n",
    "# Is the result correct?\n",
    "\n",
    "# Code here\n",
    "# Let's trace a single path: input[0] -> w_0[0,0] -> node 0 -> w_1[0,0] -> node 0 -> w_2[0,0] -> output\n",
    "\n",
    "# Save original weights\n",
    "w_0_original = w_0.copy()\n",
    "w_1_original = w_1.copy()\n",
    "w_2_original = w_2.copy()\n",
    "\n",
    "# Create weights with only one path (all zeros except one path)\n",
    "w_0_single = np.zeros_like(w_0)\n",
    "w_1_single = np.zeros_like(w_1)\n",
    "w_2_single = np.zeros_like(w_2)\n",
    "\n",
    "# Set only one path: input[0] -> hidden1[0] -> hidden2[0] -> output[0]\n",
    "w_0_single[0, 0] = w_0_original[0, 0]\n",
    "w_1_single[0, 0] = w_1_original[0, 0]\n",
    "w_2_single[0, 0] = w_2_original[0, 0]\n",
    "\n",
    "# Calculate output using the network\n",
    "hidden_1_single = np.matmul(_input, w_0_single)\n",
    "hidden_2_single = np.matmul(hidden_1_single, w_1_single)\n",
    "output_single = np.matmul(hidden_2_single, w_2_single)\n",
    "\n",
    "# Manual calculation of the same path\n",
    "manual_calculation = _input[0] * w_0_original[0, 0] * w_1_original[0, 0] * w_2_original[0, 0]\n",
    "\n",
    "print(\"Network output (single path):\", output_single)\n",
    "print(\"Manual calculation:\", manual_calculation)\n",
    "print(\"Are they equal?\", np.allclose(output_single, manual_calculation))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
